{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "\n",
    "df = pd.read_csv('input/clean_data.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words = ['and','the','to','of','infj','entp','intp','intj','entj','enfj','infp','enfp','isfp','istp','isfj','istj','estp','esfp','estj','esfj','infjs','entps','intps','intjs','entjs','enfjs','infps','enfps','isfps','istps','isfjs','istjs','estps','esfps','estjs','esfjs'], max_features=1500, analyzer=\"word\", max_df=0.8, min_df=0.1)\n",
    "\n",
    "corpus = df['clean_posts'].values.reshape(1,-1).tolist()[0]\n",
    "\n",
    "vectorizer.fit(corpus)\n",
    "\n",
    "X_cnt = vectorizer.fit_transform(corpus)\n",
    "\n",
    "X_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the count matrix to a tf-idf representation\n",
    "tfizer = TfidfTransformer()\n",
    "tfizer.fit(X_cnt)\n",
    "\n",
    "X = tfizer.fit_transform(X_cnt).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = vectorizer.get_feature_names()\n",
    "\n",
    "n_words = len(all_words)\n",
    "\n",
    "n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.DataFrame.from_dict({w: X[:, i] for i, w in enumerate(all_words)})\n",
    "\n",
    "X_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASSIFIERS GENERAL TEST BEGIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"DummyClassifier most_frequent\": DummyClassifier(strategy='most_frequent', random_state=0),\n",
    "    \"LGBMClassifier\": LGBMClassifier(),\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier(3),    \n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "    \"AdaBoostClassifier\": AdaBoostClassifier(),\n",
    "    \"GradientBoostingClassifier\": GradientBoostingClassifier(),\n",
    "    \"GaussianNB\": GaussianNB(),\n",
    "    \"LogisticRegression\": LogisticRegression(solver = 'lbfgs', max_iter=1000),\n",
    "    \"XGBClassifier\": XGBClassifier(use_label_encoder=False),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sub_classifiers_basic_test(keyword):\n",
    "    df_models = pd.DataFrame(columns=['model', 'run_time', 'avg_pre', 'avg_pre_std', 'accuracy', 'auc'])\n",
    "\n",
    "    y_df = df[keyword].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_df, \n",
    "        y_df, \n",
    "        stratify=y_df)\n",
    "\n",
    "    for key in classifiers:\n",
    "\n",
    "        print('*',key)\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        classifier = classifiers[key]\n",
    "\n",
    "        model = classifier.fit(\n",
    "            X_train, \n",
    "            y_train,\n",
    "            )\n",
    "\n",
    "        cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=5, random_state=1)\n",
    "        scorer = make_scorer(average_precision_score)\n",
    "\n",
    "        cv_scores = cross_val_score(model, X_test, y_test, cv=5, scoring=scorer)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        row = {\n",
    "            'model': key,\n",
    "            'run_time': format(round((time.time() - start_time)/60,2)),\n",
    "            'avg_pre': cv_scores.mean(),\n",
    "            'avg_pre_std': cv_scores.std(),\n",
    "            'accuracy': accuracy_score(y_test, model.predict(X_test)),\n",
    "            'auc': roc_auc_score(y_test, model.predict(X_test))\n",
    "        }\n",
    "\n",
    "        df_models = df_models.append(row, ignore_index=True)\n",
    "\n",
    "    return df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_classifiers_basic_test = sub_classifiers_basic_test(\"S_N\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_classifiers_basic_test.head(10).sort_values(by='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = 'I like to observe, think, and analyze to find cons and pros. Based on my analysis, I like to create a solution based on cost effective analysis to maximize the resource to improve the performance. I like talking to my friends. I like to read and learn. I simulate a lot of different situations to see how I would react. I read or watch a lot to improve myself. I love talking to them and seeing what they have been up to. I have a variety of friends, and I appreciate they all experience different things. Listening to their emotion, experience, and life is always great.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mbti(model, text):\n",
    "    final_test = tfizer.transform(vectorizer.transform([text.lower()])).toarray()\n",
    "\n",
    "    test_point = pd.DataFrame.from_dict({w: final_test[:, i] for i, w in enumerate(all_words)})\n",
    "\n",
    "    test_result = model.predict_proba(test_point)\n",
    "\n",
    "    return test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame(columns=['model', 'tp', 'tn', 'fp', 'fn', 'correct', 'incorrect', 'accuracy', 'precision', 'recall', 'f1', 'roc_auc','avg_pre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sub_classifier_test_01_xbg(keyword):\n",
    "    y_df = df[keyword].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_df, \n",
    "        y_df,\n",
    "        stratify=y_df)\n",
    "\n",
    "    classifier = XGBClassifier(use_label_encoder=False)\n",
    "    \n",
    "    model = classifier.fit(\n",
    "        X_train, \n",
    "        y_train,\n",
    "        early_stopping_rounds = 10, \n",
    "        eval_metric=\"logloss\", \n",
    "        eval_set=[(X_test, y_test)], verbose=False)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    avg_precision = average_precision_score(y_test, y_pred)\n",
    "\n",
    "    df_result_row = {\n",
    "            'model': 'XGBClassifier simple',\n",
    "            'tp': tp,\n",
    "            'tn': tn,\n",
    "            'fp': fp,\n",
    "            'fn': fn,\n",
    "            'correct': tp+tn,\n",
    "            'incorrect': fp+fn,\n",
    "            'accuracy': round(accuracy,3),\n",
    "            'precision': round(precision,3),\n",
    "            'recall': round(recall,3),\n",
    "            'f1': round(f1,3),\n",
    "            'roc_auc': round(roc_auc,3),\n",
    "            'avg_pre': round(avg_precision,3),\n",
    "        }\n",
    "    \n",
    "    return df_result_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_classifier_model_01_xbg(keyword):\n",
    "    y_df = df[keyword].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_df, \n",
    "        y_df,\n",
    "        stratify=y_df)\n",
    "\n",
    "    classifier = XGBClassifier(use_label_encoder=False)\n",
    "    \n",
    "    model = classifier.fit(\n",
    "        X_train, \n",
    "        y_train,\n",
    "        early_stopping_rounds = 10, \n",
    "        eval_metric=\"logloss\", \n",
    "        eval_set=[(X_test, y_test)], verbose=False)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test table row\n",
    "df_result_row_1 = sub_classifier_test_01_xbg(\"S_N\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df_result.append(df_result_row_1, ignore_index=True)\n",
    "df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier model\n",
    "sn_classifier_model_01_xbg = sub_classifier_model_01_xbg('S_N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier test\n",
    "test_mbti(sn_classifier_model_01_xbg, test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mbti(sn_classifier_model_01_xbg, 'Not sure what to say! I am pretty nervous since I am waiting here for hours.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_classifier_test_02_xbg(keyword):\n",
    "    y_df = df[keyword].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_df, \n",
    "        y_df,\n",
    "        test_size=0.3, \n",
    "        random_state=0, \n",
    "        shuffle=True, \n",
    "        stratify=y_df)\n",
    "\n",
    "    classifier = XGBClassifier(random_state=123)\n",
    "    \n",
    "    model = classifier.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    avg_precision = average_precision_score(y_test, y_pred)\n",
    "\n",
    "    df_result_row = {\n",
    "            'model': 'XGBClassifier add params',\n",
    "            'tp': tp,\n",
    "            'tn': tn,\n",
    "            'fp': fp,\n",
    "            'fn': fn,\n",
    "            'correct': tp+tn,\n",
    "            'incorrect': fp+fn,\n",
    "            'accuracy': round(accuracy,3),\n",
    "            'precision': round(precision,3),\n",
    "            'recall': round(recall,3),\n",
    "            'f1': round(f1,3),\n",
    "            'roc_auc': round(roc_auc,3),\n",
    "            'avg_pre': round(avg_precision,3),\n",
    "        }\n",
    "    \n",
    "    return df_result_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_classifier_model_02_xbg(keyword):\n",
    "    y_df = df[keyword].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_df, \n",
    "        y_df,\n",
    "        test_size=0.3, \n",
    "        random_state=0, \n",
    "        shuffle=True, \n",
    "        stratify=y_df)\n",
    "\n",
    "    classifier = XGBClassifier(random_state=123)\n",
    "    \n",
    "    model = classifier.fit(X_train, y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test table row\n",
    "df_result_row_2 = sub_classifier_test_02_xbg(\"S_N\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df_result.append(df_result_row_2, ignore_index=True)\n",
    "df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier model\n",
    "sn_classifier_model_02_xbg = sub_classifier_model_02_xbg('S_N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier test\n",
    "test_mbti(sn_classifier_model_02_xbg, test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_classifier_test_03_xbg_smote_over(keyword):\n",
    "    y_df = df[keyword].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_df, \n",
    "        y_df,\n",
    "        test_size=0.3, \n",
    "        random_state=0, \n",
    "        shuffle=True, \n",
    "        stratify=y_df)\n",
    "\n",
    "    oversampled = SMOTE(random_state=0)\n",
    "    \n",
    "    X_train_smote, y_train_smote = oversampled.fit_resample(X_train, y_train)\n",
    "\n",
    "    classifier = XGBClassifier(random_state=222)\n",
    "    \n",
    "    model = classifier.fit(X_train_smote, y_train_smote)\n",
    "    \n",
    "    y_pred_smote = model.predict(X_test)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_smote).ravel()\n",
    "    accuracy = accuracy_score(y_test, y_pred_smote)\n",
    "    precision = precision_score(y_test, y_pred_smote)\n",
    "    recall = recall_score(y_test, y_pred_smote)\n",
    "    f1 = f1_score(y_test, y_pred_smote)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_smote)\n",
    "    avg_precision = average_precision_score(y_test, y_pred_smote)\n",
    "\n",
    "    df_result_row = {\n",
    "            'model': 'XGBClassifier + SMOTE oversample',\n",
    "            'tp': tp,\n",
    "            'tn': tn,\n",
    "            'fp': fp,\n",
    "            'fn': fn,\n",
    "            'correct': tp+tn,\n",
    "            'incorrect': fp+fn,\n",
    "            'accuracy': round(accuracy,3),\n",
    "            'precision': round(precision,3),\n",
    "            'recall': round(recall,3),\n",
    "            'f1': round(f1,3),\n",
    "            'roc_auc': round(roc_auc,3),\n",
    "            'avg_pre': round(avg_precision,3),\n",
    "        }\n",
    "    \n",
    "    return df_result_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_classifier_model_03_xbg_smote_over(keyword):\n",
    "    y_df = df[keyword].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_df, \n",
    "        y_df,\n",
    "        test_size=0.3, \n",
    "        random_state=0, \n",
    "        shuffle=True, \n",
    "        stratify=y_df)\n",
    "\n",
    "    oversampled = SMOTE(random_state=0)\n",
    "    \n",
    "    X_train_smote, y_train_smote = oversampled.fit_resample(X_train, y_train)\n",
    "\n",
    "    classifier = XGBClassifier(random_state=222)\n",
    "    \n",
    "    model = classifier.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test table row\n",
    "df_result_row_3 = sub_classifier_test_03_xbg_smote_over(\"S_N\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df_result.append(df_result_row_3, ignore_index=True)\n",
    "df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier model\n",
    "sn_classifier_model_03_xbg_smote_over = sub_classifier_model_03_xbg_smote_over('S_N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier test\n",
    "test_mbti(sn_classifier_model_03_xbg_smote_over, test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XBG test 3 END\n",
    "\n",
    "# XBG test 4 BEGIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_classifier_test_04_xbg_smote_over_under(keyword):\n",
    "    y_df = df[keyword].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_df, \n",
    "        y_df,\n",
    "        test_size=0.3, \n",
    "        random_state=0, \n",
    "        shuffle=True, \n",
    "        stratify=y_df)\n",
    "\n",
    "    oversampled = SMOTE(\n",
    "        sampling_strategy=0.6, \n",
    "        random_state=0,\n",
    "        k_neighbors=4)\n",
    "    \n",
    "    X_train_smote, y_train_smote = oversampled.fit_resample(X_train, y_train)\n",
    "\n",
    "    undersampled = RandomUnderSampler(\n",
    "        sampling_strategy=0.7, \n",
    "        random_state=0)\n",
    "\n",
    "    X_train_final, y_train_final = undersampled.fit_resample(X_train_smote, y_train_smote)\n",
    "\n",
    "    classifier = XGBClassifier(random_state=222)\n",
    "    \n",
    "    model = classifier.fit(X_train_final, y_train_final)\n",
    "    \n",
    "    y_pred_smote = model.predict(X_test)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_smote).ravel()\n",
    "    accuracy = accuracy_score(y_test, y_pred_smote)\n",
    "    precision = precision_score(y_test, y_pred_smote)\n",
    "    recall = recall_score(y_test, y_pred_smote)\n",
    "    f1 = f1_score(y_test, y_pred_smote)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_smote)\n",
    "    avg_precision = average_precision_score(y_test, y_pred_smote)\n",
    "\n",
    "    df_result_row = {'model': 'XGBClassifier + SMOTE over/undersample',\n",
    "            'tp': tp,\n",
    "            'tn': tn,\n",
    "            'fp': fp,\n",
    "            'fn': fn,\n",
    "            'correct': tp+tn,\n",
    "            'incorrect': fp+fn,\n",
    "            'accuracy': round(accuracy,3),\n",
    "            'precision': round(precision,3),\n",
    "            'recall': round(recall,3),\n",
    "            'f1': round(f1,3),\n",
    "            'roc_auc': round(roc_auc,3),\n",
    "            'avg_pre': round(avg_precision,3),\n",
    "        }\n",
    "    \n",
    "    return df_result_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_classifier_model_04_xbg_smote_over_under(keyword):\n",
    "    y_df = df[keyword].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_df, \n",
    "        y_df,\n",
    "        test_size=0.3, \n",
    "        random_state=0, \n",
    "        shuffle=True, \n",
    "        stratify=y_df)\n",
    "\n",
    "    oversampled = SMOTE(\n",
    "        sampling_strategy=0.6, \n",
    "        random_state=0,\n",
    "        k_neighbors=4)\n",
    "    \n",
    "    X_train_smote, y_train_smote = oversampled.fit_resample(X_train, y_train)\n",
    "\n",
    "    undersampled = RandomUnderSampler(\n",
    "        sampling_strategy=0.7, \n",
    "        random_state=0)\n",
    "\n",
    "    X_train_final, y_train_final = undersampled.fit_resample(X_train_smote, y_train_smote)\n",
    "\n",
    "    classifier = XGBClassifier(random_state=222)\n",
    "    \n",
    "    model = classifier.fit(X_train_final, y_train_final)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test table row\n",
    "df_result_row_4 = sub_classifier_test_04_xbg_smote_over_under(\"S_N\")\n",
    "\n",
    "df_result = df_result.append(df_result_row_4, ignore_index=True)\n",
    "df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier model\n",
    "sn_classifier_model_04_xbg_smote_over_under = sub_classifier_model_04_xbg_smote_over_under('S_N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier test\n",
    "test_mbti(sn_classifier_model_04_xbg_smote_over_under, test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XBG test 4 END\n",
    "\n",
    "# XBG test 5 BEGIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_classifier_test_05_xbg_smote_borderline(keyword):\n",
    "    y_df = df[keyword].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_df, \n",
    "        y_df,\n",
    "        test_size=0.3, \n",
    "        random_state=0, \n",
    "        shuffle=True, \n",
    "        stratify=y_df)\n",
    "\n",
    "    oversampled = BorderlineSMOTE(\n",
    "        random_state=0) \n",
    "    \n",
    "    X_train_smote, y_train_smote = oversampled.fit_resample(X_train, y_train)\n",
    "\n",
    "    classifier = XGBClassifier(random_state=222)\n",
    "    \n",
    "    model = classifier.fit(X_train_smote, y_train_smote)\n",
    "    \n",
    "    y_pred_smote = model.predict(X_test)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_smote).ravel()\n",
    "    accuracy = accuracy_score(y_test, y_pred_smote)\n",
    "    precision = precision_score(y_test, y_pred_smote)\n",
    "    recall = recall_score(y_test, y_pred_smote)\n",
    "    f1 = f1_score(y_test, y_pred_smote)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_smote)\n",
    "    avg_precision = average_precision_score(y_test, y_pred_smote)\n",
    "\n",
    "    df_result_row = {'model': 'XGBClassifier with Borderline SMOTE',\n",
    "            'tp': tp,\n",
    "            'tn': tn,\n",
    "            'fp': fp,\n",
    "            'fn': fn,\n",
    "            'correct': tp+tn,\n",
    "            'incorrect': fp+fn,\n",
    "            'accuracy': round(accuracy,3),\n",
    "            'precision': round(precision,3),\n",
    "            'recall': round(recall,3),\n",
    "            'f1': round(f1,3),\n",
    "            'roc_auc': round(roc_auc,3),\n",
    "            'avg_pre': round(avg_precision,3),\n",
    "        }\n",
    "    \n",
    "    return df_result_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_classifier_model_05_xbg_smote_borderline(keyword):\n",
    "    y_df = df[keyword].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_df, \n",
    "        y_df,\n",
    "        test_size=0.3, \n",
    "        random_state=0, \n",
    "        shuffle=True, \n",
    "        stratify=y_df)\n",
    "\n",
    "    oversampled = BorderlineSMOTE(\n",
    "        random_state=0) \n",
    "    \n",
    "    X_train_smote, y_train_smote = oversampled.fit_resample(X_train, y_train)\n",
    "\n",
    "    classifier = XGBClassifier(random_state=222)\n",
    "    \n",
    "    model = classifier.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test table row\n",
    "df_result_row_5 = sub_classifier_test_05_xbg_smote_borderline(\"S_N\")\n",
    "\n",
    "df_result = df_result.append(df_result_row_5, ignore_index=True)\n",
    "df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier model\n",
    "sn_classifier_model_05_xbg_smote_borderline = sub_classifier_model_05_xbg_smote_borderline('S_N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier test\n",
    "test_mbti(sn_classifier_model_05_xbg_smote_borderline, test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv('xgb_classifier_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost + SMOTE over/undersample Test on all 4 classes BEGIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_result = pd.DataFrame(columns=['class', 'tp', 'tn', 'fp', 'fn', 'correct', 'incorrect', 'accuracy', 'precision', 'recall', 'f1', 'roc_auc','avg_pre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_classifier_test_06_xbg_smote_over_under(keyword):\n",
    "    y_df = df[keyword].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_df, \n",
    "        y_df,\n",
    "        test_size=0.3, \n",
    "        random_state=0, \n",
    "        shuffle=True, \n",
    "        stratify=y_df)\n",
    "\n",
    "    oversampled = SMOTE(\n",
    "        sampling_strategy=0.6, \n",
    "        random_state=0,\n",
    "        k_neighbors=4)\n",
    "    \n",
    "    X_train_smote, y_train_smote = oversampled.fit_resample(X_train, y_train)\n",
    "\n",
    "    undersampled = RandomUnderSampler(\n",
    "        sampling_strategy=0.7, \n",
    "        random_state=0)\n",
    "\n",
    "    X_train_final, y_train_final = undersampled.fit_resample(X_train_smote, y_train_smote)\n",
    "\n",
    "    classifier = XGBClassifier(random_state=222)\n",
    "    \n",
    "    model = classifier.fit(X_train_final, y_train_final)\n",
    "    \n",
    "    y_pred_smote = model.predict(X_test)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_smote).ravel()\n",
    "    accuracy = accuracy_score(y_test, y_pred_smote)\n",
    "    precision = precision_score(y_test, y_pred_smote)\n",
    "    recall = recall_score(y_test, y_pred_smote)\n",
    "    f1 = f1_score(y_test, y_pred_smote)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_smote)\n",
    "    avg_precision = average_precision_score(y_test, y_pred_smote)\n",
    "\n",
    "    df_result_row = {\n",
    "            'class': keyword,\n",
    "            'tp': tp,\n",
    "            'tn': tn,\n",
    "            'fp': fp,\n",
    "            'fn': fn,\n",
    "            'correct': tp+tn,\n",
    "            'incorrect': fp+fn,\n",
    "            'accuracy': round(accuracy,3),\n",
    "            'precision': round(precision,3),\n",
    "            'recall': round(recall,3),\n",
    "            'f1': round(f1,3),\n",
    "            'roc_auc': round(roc_auc,3),\n",
    "            'avg_pre': round(avg_precision,3),\n",
    "        }\n",
    "    \n",
    "    return df_result_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_classifier_test_07_xbg_smote_over(keyword):\n",
    "    y_df = df[keyword].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_df, \n",
    "        y_df,\n",
    "        test_size=0.3, \n",
    "        random_state=0, \n",
    "        shuffle=True, \n",
    "        stratify=y_df)\n",
    "\n",
    "    oversampled = SMOTE(random_state=0)\n",
    "    \n",
    "    X_train_smote, y_train_smote = oversampled.fit_resample(X_train, y_train)\n",
    "\n",
    "    classifier = XGBClassifier(random_state=222)\n",
    "    \n",
    "    model = classifier.fit(X_train_smote, y_train_smote)\n",
    "    \n",
    "    y_pred_smote = model.predict(X_test)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_smote).ravel()\n",
    "    accuracy = accuracy_score(y_test, y_pred_smote)\n",
    "    precision = precision_score(y_test, y_pred_smote)\n",
    "    recall = recall_score(y_test, y_pred_smote)\n",
    "    f1 = f1_score(y_test, y_pred_smote)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_smote)\n",
    "    avg_precision = average_precision_score(y_test, y_pred_smote)\n",
    "\n",
    "    df_result_row = {\n",
    "            'class': keyword,\n",
    "            'tp': tp,\n",
    "            'tn': tn,\n",
    "            'fp': fp,\n",
    "            'fn': fn,\n",
    "            'correct': tp+tn,\n",
    "            'incorrect': fp+fn,\n",
    "            'accuracy': round(accuracy,3),\n",
    "            'precision': round(precision,3),\n",
    "            'recall': round(recall,3),\n",
    "            'f1': round(f1,3),\n",
    "            'roc_auc': round(roc_auc,3),\n",
    "            'avg_pre': round(avg_precision,3),\n",
    "        }\n",
    "    \n",
    "    return df_result_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E_I test table row\n",
    "df_ei_result_row = sub_classifier_test_06_xbg_smote_over_under(\"E_I\")\n",
    "\n",
    "df_all_result = df_all_result.append(df_ei_result_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S_N test table row\n",
    "df_sn_result_row = sub_classifier_test_06_xbg_smote_over_under(\"S_N\")\n",
    "\n",
    "df_all_result = df_all_result.append(df_sn_result_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T_F test table row\n",
    "df_tf_result_row = sub_classifier_test_07_xbg_smote_over(\"T_F\")\n",
    "\n",
    "df_all_result = df_all_result.append(df_tf_result_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# J_P test table row\n",
    "df_jp_result_row = sub_classifier_test_07_xbg_smote_over(\"J_P\")\n",
    "\n",
    "df_all_result = df_all_result.append(df_jp_result_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_result.to_csv('xgb_classifier_all_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost + SMOTE over/undersample Test on all 4 classes END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ei_classifier_model = sub_classifier_model_04_xbg_smote_over_under('E_I')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_classifier_model = sub_classifier_model_04_xbg_smote_over_under('S_N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_classifier_model = sub_classifier_model_03_xbg_smote_over('T_F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jp_classifier_model = sub_classifier_model_03_xbg_smote_over('J_P')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpdesk_topic = \"To Whom It May Concern, I am writing today to complain of the poor service I received from your company on June 12, 2020. I was visited by a representative of That Awful Company, Mr. Madman, at my home on that day. I trust this is not the way That Awful Company wishes to conduct business with valued customers—I have been with you since the company was founded and have never encountered such treatment before. I would welcome the opportunity to discuss matters further and to learn of how you propose to prevent a similar situation from recurring. I look forward to hearing from you. Yours faithfully, Customer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mbti(ei_classifier_model, helpdesk_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mbti(sn_classifier_model, helpdesk_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mbti(tf_classifier_model, helpdesk_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mbti(jp_classifier_model, helpdesk_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('mbti_01')",
   "name": "python394jvsc74a57bd0cb2a74056668a37b1e70d58465c542cd41f068be1a294d62341136952e9c6170"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "metadata": {
   "interpreter": {
    "hash": "cb2a74056668a37b1e70d58465c542cd41f068be1a294d62341136952e9c6170"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
